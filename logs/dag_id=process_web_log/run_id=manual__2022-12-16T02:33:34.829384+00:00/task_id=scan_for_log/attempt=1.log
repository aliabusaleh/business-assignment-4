[2022-12-16 02:33:37,264] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: process_web_log.scan_for_log manual__2022-12-16T02:33:34.829384+00:00 [queued]>
[2022-12-16 02:33:37,276] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: process_web_log.scan_for_log manual__2022-12-16T02:33:34.829384+00:00 [queued]>
[2022-12-16 02:33:37,276] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2022-12-16 02:33:37,276] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2022-12-16 02:33:37,276] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2022-12-16 02:33:37,291] {taskinstance.py:1377} INFO - Executing <Task(_PythonDecoratedOperator): scan_for_log> on 2022-12-16 02:33:34.829384+00:00
[2022-12-16 02:33:37,297] {standard_task_runner.py:52} INFO - Started process 368 to run task
[2022-12-16 02:33:37,301] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'process_web_log', 'scan_for_log', 'manual__2022-12-16T02:33:34.829384+00:00', '--job-id', '30', '--raw', '--subdir', 'DAGS_FOLDER/test1.py', '--cfg-path', '/tmp/tmppygynwoh', '--error-file', '/tmp/tmp29yo2sxm']
[2022-12-16 02:33:37,301] {standard_task_runner.py:80} INFO - Job 30: Subtask scan_for_log
[2022-12-16 02:33:37,360] {task_command.py:369} INFO - Running <TaskInstance: process_web_log.scan_for_log manual__2022-12-16T02:33:34.829384+00:00 [running]> on host 411836952c8f
[2022-12-16 02:33:37,424] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=process_web_log
AIRFLOW_CTX_TASK_ID=scan_for_log
AIRFLOW_CTX_EXECUTION_DATE=2022-12-16T02:33:34.829384+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-12-16T02:33:34.829384+00:00
[2022-12-16 02:33:37,427] {test1.py:53} WARNING - scanning a folder 
[2022-12-16 02:33:37,438] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 179, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 171, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 189, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/test1.py", line 54, in scan_a_folder
    scan_for_log_task = FileSensor( task_id= "scan_for_log", poke_interval= 1, filepath= './the_log/', dag=dag )
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/sensors/filesystem.py", line 49, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/sensors/base.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 764, in __init__
    task_group.add(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/task_group.py", line 196, in add
    raise DuplicateTaskIdFound(f"{node_type} id '{key}' has already been added to the DAG")
airflow.exceptions.DuplicateTaskIdFound: Task id 'scan_for_log' has already been added to the DAG
[2022-12-16 02:33:37,442] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=process_web_log, task_id=scan_for_log, execution_date=20221216T023334, start_date=20221216T023337, end_date=20221216T023337
[2022-12-16 02:33:37,454] {standard_task_runner.py:97} ERROR - Failed to execute job 30 for task scan_for_log (Task id 'scan_for_log' has already been added to the DAG; 368)
[2022-12-16 02:33:37,475] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-12-16 02:33:37,502] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
